{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR:** Initial full attempt resulted in only ~0.5 accuracy on full sample; clearly something is off. Speculated that this was due to the truncated vocabulary used still being too large, and/or not lemmatising, resulting in an inadequate (noisy and/or lossy) word2vec representation. Haven't finished testing this idea yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/training.1600000.processed.noemoticon.csv', header=None, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.rename(columns = { 0: 'positive', 5: 'tweet' }, inplace=True)\n",
    "tweets = tweets[['positive', 'tweet']]\n",
    "tweets.loc[:, 'positive'] = (tweets.positive == 4).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify number of terms (size of vocabulary) to consider\n",
    "using IDF (inverse document frequency) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer()\n",
    "doc_terms = vectoriser.fit_transform(tweets.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=684358, minmax=(2.250207176415574, 14.59236763164987), mean=14.211100645629408, variance=0.7161283022424955, skewness=-3.981211810930763, kurtosis=22.023923629571634)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(vectoriser.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x152c68b00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(vectoriser.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_words = pd.Series(list(vectoriser.vocabulary_.keys()), index=list(vectoriser.vocabulary_.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idxs_invfreq_sorted = np.argsort(vectoriser.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613861      to\n",
       "600797     the\n",
       "433663      my\n",
       "68527      and\n",
       "300094      it\n",
       "675497     you\n",
       "299013      is\n",
       "235685     for\n",
       "293405      in\n",
       "458032      of\n",
       "462013      on\n",
       "402259      me\n",
       "600330    that\n",
       "563436      so\n",
       "269160    have\n",
       "124252     but\n",
       "330392    just\n",
       "658180    with\n",
       "95144       be\n",
       "82734       at\n",
       "452789     not\n",
       "648494     was\n",
       "453592     now\n",
       "607680    this\n",
       "128986     can\n",
       "634734      up\n",
       "255508    good\n",
       "177229     day\n",
       "61704      all\n",
       "466370     out\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_words[word_idxs_invfreq_sorted].iloc[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where do the terms stop making sense?\n",
    "Finding a threshold at which to exclude terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95687               beary\n",
       "571682            squiffy\n",
       "390977          mamzellef\n",
       "223551              facit\n",
       "657158             winder\n",
       "421653      mollyschambrs\n",
       "45432              _nathy\n",
       "383288           luscious\n",
       "647266              walao\n",
       "182537           denicesy\n",
       "421651             mollys\n",
       "428031           mrscantz\n",
       "661779               wren\n",
       "574077             startd\n",
       "561892              smont\n",
       "538452      scizzorwizard\n",
       "204198           ebbsbaby\n",
       "204321          ebonyeeee\n",
       "329413            julieem\n",
       "451393             nolans\n",
       "576239    stephy_michelle\n",
       "390851          mameekins\n",
       "95752             beatccr\n",
       "217586          esperanto\n",
       "616901               tope\n",
       "576253       stephylouise\n",
       "676373              youur\n",
       "150959            cleaver\n",
       "337146          katiekayx\n",
       "341782               kens\n",
       "217623          esplanade\n",
       "24598              5years\n",
       "223269          fabulista\n",
       "552565           shrnclrk\n",
       "483119           pinkpebs\n",
       "183000              depan\n",
       "29454               6emqk\n",
       "652839         whaaaaaaat\n",
       "209842        ellifordyce\n",
       "348711                klm\n",
       "557861             skewed\n",
       "461092       olorinlorien\n",
       "552592               shrt\n",
       "223339             facade\n",
       "579028             strata\n",
       "317740              jhsty\n",
       "10397                 295\n",
       "151030            clement\n",
       "423590           mooching\n",
       "95714             beastin\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_words[word_idxs_invfreq_sorted].iloc[50000:50050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181201             deidra\n",
       "556980             sittig\n",
       "682301            zuhiboy\n",
       "388147         magda_m_78\n",
       "677226               yule\n",
       "138447           chandrat\n",
       "575933       stephenshuai\n",
       "376474        lollingtons\n",
       "679376               zajÃ£\n",
       "13399           30million\n",
       "181062    defyingdestinyy\n",
       "111968             bonyok\n",
       "673193             yeeeuh\n",
       "124545        butterworth\n",
       "13397               30mil\n",
       "394623          marjorie5\n",
       "557082              siwon\n",
       "162135           craig563\n",
       "151464         clioawards\n",
       "584323       supercricket\n",
       "181057     defygravity213\n",
       "102541             bhajji\n",
       "124552           buttfuck\n",
       "388101              magan\n",
       "557065            sivi911\n",
       "557066          sivinjski\n",
       "607624            thirdly\n",
       "673191              yeeet\n",
       "601576         theatricel\n",
       "557069      siviwekwatsha\n",
       "162124            craggsc\n",
       "584329    supercutsaustin\n",
       "181073          degadeals\n",
       "417611         misterslim\n",
       "162125            cragnet\n",
       "677220               yuky\n",
       "181072               dega\n",
       "2496                 1192\n",
       "102538             bhaiya\n",
       "151463           clio_jlh\n",
       "138505             changa\n",
       "138506           changa13\n",
       "584320        supercracko\n",
       "13386           30legends\n",
       "151454        clintrutkas\n",
       "181036         defsupreme\n",
       "388090          magalinee\n",
       "376494      lollipopvomit\n",
       "417605        mistersaxon\n",
       "181034          defsounds\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_words[word_idxs_invfreq_sorted].iloc[200000:200050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607611         thirdbase7\n",
       "402468            meanbot\n",
       "394633      marjoysaerang\n",
       "138523         changecamp\n",
       "102561              bhane\n",
       "151449       clintonwayne\n",
       "388086          magali777\n",
       "117871           bridgers\n",
       "569512         sphynxeyes\n",
       "402490           meanieee\n",
       "376492      lollipopswirl\n",
       "601586     theauroraprjct\n",
       "13394                30mi\n",
       "557085               siwy\n",
       "124543        buttertoast\n",
       "417610        misterskull\n",
       "102547            bhalash\n",
       "402478    meandmybigmouth\n",
       "117861      bridgelicious\n",
       "682273             zucker\n",
       "593556            tashiam\n",
       "394628       marjoriemliu\n",
       "429455              msiou\n",
       "138518     change_clothes\n",
       "402471              meand\n",
       "102554             bhambo\n",
       "102555         bhamboxset\n",
       "181039            deftlyd\n",
       "162099         craftyhope\n",
       "138487       chanelraquel\n",
       "138483       chanellybaby\n",
       "429477         msjaebella\n",
       "138461       chaneldanise\n",
       "181120            degreee\n",
       "388112            magaret\n",
       "593541          tashboard\n",
       "569525          spiceflow\n",
       "593540          tashbg0sh\n",
       "429476            msjadis\n",
       "162109          craftypod\n",
       "557040              siuiv\n",
       "181114     degrassinsider\n",
       "102525            bhahaha\n",
       "376447            lolland\n",
       "102526           bhahahah\n",
       "394612        marjokris09\n",
       "421770             mom_11\n",
       "429478       msjaidarenee\n",
       "601569      theatresports\n",
       "597815            tennent\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_words[word_idxs_invfreq_sorted].iloc[200050:200100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200,000 looks like a safe cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise (and reassemble) Tweets to include only 200,000 most frequent terms\n",
    "\n",
    "This is clearly clunky, but it's the best I can do with Tokenizer's current interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = Tokenizer(num_words=200001)\n",
    "tokeniser.fit_on_texts(tweets.tweet)\n",
    "tweets.tweet = tokeniser.sequences_to_texts(tokeniser.texts_to_sequences(tweets.tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('data/training.1600000.cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write vocabulary into file compatible with word2vec input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = 'data/tweet_vocab_200000.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(vocab_file, 'w')\n",
    "f.write(tweets.tweet.str.cat(sep=' '))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using vocabulary file and write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_vectors_file = 'data/tweet_vocab_200000_vectors.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file data/tweet_vocab_200000.txt\n",
      "Vocab size: 200001\n",
      "Words in train file: 21045754\n",
      "Alpha: 0.000024  Progress: 99.92%  Words/thread/sec: 277.68k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2vec(vocab_file, vocab_vectors_file, size=100, min_count=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the vocab size one larger than it should be...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lists of vectors for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.load(vocab_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(t):\n",
    "    if t in word2vec_model:\n",
    "        return word2vec_model[t]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['vectors'] = tweets.tweet.apply(lambda tweet: list(map(lambda t: get_vector(t), tweet.split())))\n",
    "tweets['vectors'] = tweets.vectors.apply(lambda vecs: np.array([v for v in vecs if len(v) > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad list of vectors for each Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_vectors = sequence.pad_sequences(tweets.vectors, dtype=np.float64, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will free up memory and hopefully keep the kernel from dying (as used on my laptop)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(columns='vectors', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning under time constraints: based on data subsample\n",
    "I know this isn't kosher, but I have a deadline, and hopefully it works well enough for my present purposes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select random subsample for \"cross-validation\"\n",
    "I tried to sample random indices at one go, then select the indexed observations, but my kernel kept dying. Iterating over smaller chunks then aggregating the results seems to be more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_train_x_chunks, tuning_train_y_chunks = [], []\n",
    "increment, iter_n = 200000, 8000\n",
    "for i in range(8):\n",
    "    start = i * increment\n",
    "    tuning_train_idx = np.random.randint(start, start + increment, size=iter_n)\n",
    "    tuning_train_x_chunks.append(padded_vectors[tuning_train_idx])\n",
    "    y = tweets.positive.iloc[tuning_train_idx].values\n",
    "    tuning_train_y_chunks.append(np.reshape(y, (y.shape[0], -1)))\n",
    "tuning_train_x = np.vstack(tuple(tuning_train_x_chunks))\n",
    "tuning_train_y = np.vstack(tuple(tuning_train_y_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tuning_train_x_chunks, tuning_train_y_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_shuffled_idxs = np.arange(tuning_train_x.shape[0])\n",
    "np.random.shuffle(tuning_shuffled_idxs)\n",
    "tuning_train_x = tuning_train_x[tuning_shuffled_idxs]\n",
    "tuning_train_y = tuning_train_y[tuning_shuffled_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(lstm_units, lstm_do, lstm_recurr_do, dense_units, dense_activ, dense_do, opt):\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, return_sequences=False, dropout=lstm_do, recurrent_dropout=lstm_recurr_do))\n",
    "    model.add(Dense(dense_units, activation=dense_activ))\n",
    "    model.add(Dropout(dense_do))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_indices(i, k, index):\n",
    "    if i < 1 or i > k:\n",
    "        raise ValueError\n",
    "    step, n = 1.0 / k, len(index)\n",
    "    lb, ub = round((i-1) * step * n), round(i * step * n)\n",
    "    include = list(range(lb))\n",
    "    include.extend(range(ub, n)) \n",
    "    exclude = list(range(lb, ub))\n",
    "    return index[exclude], index[include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not really k-fold CV, since the model isn't reinstantiated (i.e. weights are carried over from previous\n",
    "## fold trainings), but c.f. time constraints\n",
    "# def k_fold_cv(x, y, k, model, cv_verbose=False, **kwargs):\n",
    "#     accuracy = np.zeros(k)\n",
    "#     stdevs = np.zeros(k)\n",
    "#     for i in range(1, k+1):\n",
    "#         if cv_verbose:\n",
    "#             print('fold ', i)\n",
    "#         exclude, include = partition_indices(i, k, np.arange(x.shape[0]))\n",
    "#         x_fit = x[include]\n",
    "#         model.fit(x_fit, y[include], **kwargs)\n",
    "#         exclude_len = len(x[exclude])\n",
    "#         predictions = np.round(model.predict(x[exclude]))\n",
    "#         corrects = (predictions == y[exclude]).astype(int)\n",
    "#         accuracy[i-1] = corrects.mean()\n",
    "#         stdevs[i-1] = corrects.std()\n",
    "#     return accuracy, stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_iter(x, y, i, k, model, cv_verbose=False, **kwargs):\n",
    "    exclude, include = partition_indices(i, k, np.arange(x.shape[0]))\n",
    "    x_fit = x[include]\n",
    "    model.fit(x_fit, y[include], **kwargs)\n",
    "    exclude_len = len(x[exclude])\n",
    "    predictions = np.round(model.predict(x[exclude]))\n",
    "    return (predictions == y[exclude]).astype(int).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First pass (well, after a few undocumented trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 60s 1ms/sample - loss: 5.9437e-08 - accuracy: 0.4938\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9437e-08 - accuracy: 0.4946\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9437e-08 - accuracy: 0.4937\n",
      "fold  2\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 60s 1ms/sample - loss: 5.9621e-08 - accuracy: 0.4947\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 56s 1ms/sample - loss: 5.9621e-08 - accuracy: 0.4967\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9621e-08 - accuracy: 0.4928\n",
      "fold  3\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 61s 1ms/sample - loss: 5.9719e-08 - accuracy: 0.5048\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9719e-08 - accuracy: 0.5024\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 56s 1ms/sample - loss: 5.9719e-08 - accuracy: 0.5052\n",
      "fold  4\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 61s 1ms/sample - loss: 5.9551e-08 - accuracy: 0.5062\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9551e-08 - accuracy: 0.5046\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9551e-08 - accuracy: 0.5046\n",
      "fold  5\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 63s 1ms/sample - loss: 5.9695e-08 - accuracy: 0.5094\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 60s 1ms/sample - loss: 5.9695e-08 - accuracy: 0.5093\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9695e-08 - accuracy: 0.5101\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros(5)\n",
    "for i in range(1, 6):\n",
    "    print('fold ', i)\n",
    "    accuracies[i-1] = k_fold_cv_iter(tuning_train_x, tuning_train_y, i, 5,\n",
    "                                     get_model(128, 0.1, 0.1, 32, 'relu', 0.5, 'RMSprop'), epochs=3, batch_size=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50976562, 0.49148437, 0.51351563, 0.5146875 , 0.5190625 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 74s 1ms/sample - loss: 5.9535e-08 - accuracy: 0.5137\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 61s 1ms/sample - loss: 5.9535e-08 - accuracy: 0.5108\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 59s 1ms/sample - loss: 5.9535e-08 - accuracy: 0.5116\n",
      "fold  2\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 61s 1ms/sample - loss: 5.9626e-08 - accuracy: 0.5096\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9626e-08 - accuracy: 0.5101\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9626e-08 - accuracy: 0.5105\n",
      "fold  3\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 63s 1ms/sample - loss: 5.9728e-08 - accuracy: 0.5025\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9728e-08 - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9728e-08 - accuracy: 0.4987\n",
      "fold  4\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 63s 1ms/sample - loss: 5.9567e-08 - accuracy: 0.5188\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9567e-08 - accuracy: 0.5189\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 59s 1ms/sample - loss: 5.9567e-08 - accuracy: 0.5198\n",
      "fold  5\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 64s 1ms/sample - loss: 5.9567e-08 - accuracy: 0.4884\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9567e-08 - accuracy: 0.4861\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 60s 1ms/sample - loss: 5.9567e-08 - accuracy: 0.4923\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros(5)\n",
    "for i in range(1, 6):\n",
    "    print('fold ', i)\n",
    "    accuracies[i-1] = k_fold_cv_iter(tuning_train_x, tuning_train_y, i, 5,\n",
    "                                     get_model(128, 0.1, 0.1, 64, 'relu', 0.5, 'RMSprop'), epochs=3, batch_size=1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 13/6/2020: Maybe that subsampling idea was dumb? I've spent much of my time trying to get the kernel not to die, and gotten not much farther from where I started. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDER CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53523438, 0.50351563, 0.50929687, 0.52984375, 0.45015625])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 66s 1ms/sample - loss: 5.9535e-08 - accuracy: 0.5163\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 59s 1ms/sample - loss: 5.9535e-08 - accuracy: 0.5185\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 58s 1ms/sample - loss: 5.9535e-08 - accuracy: 0.5183\n",
      "fold  2\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 63s 1ms/sample - loss: 5.9626e-08 - accuracy: 0.4826\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9626e-08 - accuracy: 0.4824\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 57s 1ms/sample - loss: 5.9626e-08 - accuracy: 0.4837\n",
      "fold  3\n",
      "Train on 51200 samples\n",
      "Epoch 1/3\n",
      "51200/51200 [==============================] - 64s 1ms/sample - loss: 5.9728e-08 - accuracy: 0.4907\n",
      "Epoch 2/3\n",
      "51200/51200 [==============================] - 59s 1ms/sample - loss: 5.9728e-08 - accuracy: 0.4903\n",
      "Epoch 3/3\n",
      "51200/51200 [==============================] - 59s 1ms/sample - loss: 5.9728e-08 - accuracy: 0.4917\n",
      "fold  4\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros(5)\n",
    "for i in range(1, 6):\n",
    "    print('fold ', i)\n",
    "    accuracies[i-1] = k_fold_cv_iter(tuning_train_x, tuning_train_y, i, 5,\n",
    "                                     get_model(128, 0.1, 0.1, 32, 'relu', 0.2, 'RMSprop'),\n",
    "                                     epochs=3, batch_size=1600, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM (64, 0.1, 0.1), dense (64, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adadelta: 0.4037, 0.4049, 0.4066, 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop: 0.4469, 0.4444, 0.4479, 0.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM (128, 0.1), dense (32, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop: 0.4952, 0.5015, 0.4979, 0.46"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
